"""
ae_pipeline_simple.py

é¡ºåºåšä¸‰ä»¶äº‹ï¼Œä½†åªè¾“å‡ºæœ€ç»ˆä¸€ä¸ªç»“æœ CSVï¼š
1) ç”¨ Azure GPT-4o ä» notes é‡ŒæŠ½ AE
2) ï¼ˆå¯é€‰ï¼‰ç”¨ baseline è¿‡æ»¤æ‰ baseline ä»¥å†…çš„ AE
3) ç”¨ä½ å¾®è°ƒå¥½çš„ MedCPT æ¨¡å‹æ˜ å°„åˆ° CTCAE v5.0

æœ€ç»ˆè¾“å‡ºä¸€ä¸ªè¡¨ï¼Œåˆ—å¤§è‡´ä¸ºï¼š
MRN, Onset Date, Date Resolved, CTCAE, Grade,
Attr to Disease, AE Immune related?, Serious Y/N,
CTCAE_Mapped_Top1, Similarity_Top1, Final_CTCAE_Term
"""

import time
import json
import pandas as pd
import torch
import torch.nn.functional as F
from transformers import AutoTokenizer, AutoModel
from openai import AzureOpenAI
from incremental_update import update_patient_history


# ================= 0. Azure GPT å®¢æˆ·ç«¯ =================
client = AzureOpenAI(
    api_version="2024-12-01-preview",
    azure_endpoint="https://bionlp-ge.openai.azure.com/",
    api_key=""
)


# ================= 1. GPT æå– AE çš„ prompt =================
base_prompt = """
You are a clinical research assistant helping to extract adverse events (AEs) from clinical notes.
Note:
<text>
{text}
</text>

For each AE, extract the following fields **in JSON array format** (one object per AE):

- MRN (from the note)
- Onset Date: If a specific start date is mentioned, extract it directly; otherwise, use the clinic note date as the start date or estimate an onset date according to the notes. "Onset Date" MUST NEVER be "Unknown" or "unknown". For any AE, if no explicit onset date is mentioned, ALWAYS set "Onset Date" exactly to {doc_date} (or date (estimated)), never to "Unknown".
- Date Resolved: If a specific end date or resolution (â€œâ€¦has resolvedâ€) is mentioned, extract it; for events like â€œweight loss â†’ gain weight,â€ use the clinic note date as the end date. If the AE is described as ongoing, set end date to â€œongoing.â€ If not mentioned, set end date to â€œunknown.â€
- AE term (mapped to CTCAE terminology)
- Grade (must be 1 to 5) If grade is not explicitly stated, estimate it based on context (Grade 1 for mild, Grade 2 if moderate/intervention needed, Grade 3 if Severe pain; Grade 4 if Life-threatening).
- Attribution to Disease? One of [Unrelated, Unlikely, Possible, Probable, and Definite]
- Immune-related AE? (Yes/No): Mark â€œYesâ€ if the AE is immune-related (irAE) based on the following definition.
Definition of immune-related adverse events (irAEs):irAEs are adverse events relevant to immunotherapy, such as colitis, thyroiditis, hypophysitis, adrenalitis, myositis, myocarditis, encephalitis, pneumonitis, hepatitis, immunotherapy-induced diabetes mellitus, vitiligo, and similar conditions. If the AE is immune-mediated or commonly recognized as an irAE, mark â€œYesâ€; otherwise, mark â€œNoâ€.
- serious AE? (Yes/No) Mark â€œYesâ€ if the AE is considered serious (e.g., life-threatening, hospitalization, or significant disability); otherwise, â€œNo.â€

**Important**:

Use the note date (if known) to anchor temporal reasoning.

Do not ignore symptoms that are briefly mentioned, appear together with other events, or are described with mild tone. Even minor or vague symptoms should be extracted.

If multiple symptoms are listed in one sentence, treat them as distinct AEs, and extract each separately.

Also extract imaging-based AEs that are not explicitly labeled as diagnoses but can be inferred from radiology findings such as CT scans.

Note any symptoms or minor symptoms that are mentioned as resolved. it should still be extracted and recorded, with end date set to resolution date if known, or clinic note date otherwise.

If no adverse events are present, return an empty JSON array: []
Do NOT include any explanation. Only return the JSON array.

Return a JSON array. Each AE MUST be a JSON object with EXACTLY the following keys
(using the same spelling and capitalization):

[
  {{
    "MRN": "...",
    "Onset Date": "...",
    "Date Resolved": "...",
    "AE Term": "...",
    "Grade": "...",
    "Attribution to Disease": "...",
    "Immune-related AE": "Yes" or "No",
    "Serious AE": "Yes" or "No"
  }}
]

Use these keys EXACTLY as written. 
Do NOT add question marks, extra spaces, or any additional keys.
Do NOT change capitalization.

Patient info:
MRN: {mrn}
Document Date: {doc_date}
Document Name: {doc_name}
"""


# ============= å‡½æ•° 1ï¼šGPTï¼Œä» notes CSV -> AE DataFrameï¼ˆä»…åœ¨å†…å­˜ï¼‰ =============
def gpt_extract_ae(note_csv_path: str) -> pd.DataFrame:
    df = pd.read_csv(note_csv_path)[43:44]

    structured_results = []

    for i, row in df.iterrows():
        prompt = base_prompt.format(
            text=row["Document Text"],
            mrn=row["mrn"],
            doc_date=row["Document Date"],
            doc_name=row["Document Name"],
        )

        print(f"\n=== GPT Step | row {i} | MRN: {row['mrn']} ===")

        try:
            response = client.chat.completions.create(
                model="gpt-4o",  # å¦‚æœä½ çš„ deployment åä¸åŒï¼Œè¿™é‡Œæ”¹åå­—
                messages=[{"role": "user", "content": prompt}],
                temperature=0,
                max_tokens=2048,
            )
            reply = response.choices[0].message.content.strip()

            # è§£æ JSON æ•°ç»„
            json_start = reply.find("[")
            json_end = reply.rfind("]") + 1
            json_text = reply[json_start:json_end]

            if not (json_text.startswith("[") and json_text.endswith("]")):
                print(f"âš ï¸ Row {i}: Not a valid JSON array. Skipping.")
                continue

            ae_list = json.loads(json_text)
            if not isinstance(ae_list, list) or len(ae_list) == 0:
                print(f"â„¹ï¸ Row {i}: No AE extracted.")
                continue

            for ae in ae_list:
                ae["Document Date"] = row["Document Date"]
                ae["Document Name"] = row["Document Name"]
                structured_results.append(ae)

        except Exception as e:
            print(f"âŒ Error on row {i}: {e}")
            continue

        time.sleep(1)

    ae_df = pd.DataFrame(structured_results)

    if ae_df.empty:
        print("âš ï¸ GPT æ²¡æœ‰æŠ½åˆ°ä»»ä½• AEã€‚")
        return ae_df

    # æ ‡å‡†åŒ–å‡ åˆ—ï¼Œåé¢ filter / mapping è¦ç”¨
    ae_df["MRN"] = ae_df["MRN"].astype(str).str.strip()
    ae_df["CTCAE"] = ae_df["AE Term"].astype(str).str.strip().str.lower()
    ae_df["Grade"] = pd.to_numeric(ae_df["Grade"], errors="coerce")

    return ae_df


# ============= å‡½æ•° 2ï¼šbaseline filterï¼ˆå¯é€‰ï¼‰ =============
def filter_with_baseline(ae_df: pd.DataFrame, baseline_file: str | None) -> pd.DataFrame:
    """å¦‚æœ baseline_file æ˜¯ None æˆ– ""ï¼Œåˆ™ç›´æ¥è¿”å› ae_dfï¼Œä¸åšä»»ä½•è¿‡æ»¤ã€‚"""
    if ae_df.empty:
        return ae_df

    if baseline_file is None or baseline_file == "":
        print("â„¹ï¸ æœªæä¾› baseline æ–‡ä»¶ï¼Œè·³è¿‡ baseline è¿‡æ»¤ã€‚")
        return ae_df

    baseline_df = pd.read_excel(baseline_file)
    baseline_df.columns = baseline_df.columns.str.strip()

    # å…³é”®åˆ—åï¼ˆæŒ‰ä½ ä¹‹å‰çš„è„šæœ¬ï¼‰
    subject_col = "Patient"
    ae_term_col = "Adverse Event Term (v5.0)"
    baseline_grade_col = "Grade"  # baseline AE grade åˆ—
    ae_grade_col = "Grade"        # æˆ‘ä»¬ AE è¡¨é‡Œçš„ Grade åˆ—

    # baseline æ ‡å‡†åŒ–
    baseline_df[subject_col] = baseline_df[subject_col].astype(str).str.strip()
    baseline_df[ae_term_col] = (
        baseline_df[ae_term_col].astype(str).str.strip().str.lower()
    )
    baseline_df[baseline_grade_col] = (
        baseline_df[baseline_grade_col]
        .astype(str)
        .str.extract(r"(\d+)")
        .astype(float)
    )

    merged = ae_df.merge(
        baseline_df[[subject_col, ae_term_col, baseline_grade_col]],
        how="left",
        left_on=["MRN", "CTCAE"],
        right_on=[subject_col, ae_term_col],
        suffixes=("", "_baseline"),
    )

    ae_grade = merged[ae_grade_col]
    baseline_grade = merged["Grade_baseline"].fillna(-1)

    keep_mask = ae_grade > baseline_grade
    filtered_df = merged[keep_mask]

    filtered_df = filtered_df[ae_df.columns]
    print(f"âœ… baseline filterï¼šä» {len(ae_df)} æ¡ AE ä¿ç•™ {len(filtered_df)} æ¡")
    return filtered_df


# ============= å‡½æ•° 3ï¼šMedCPT æ˜ å°„ CTCAEï¼ˆae_df -> final_dfï¼‰ =============
def map_to_ctcae_medcpt(
    ae_df: pd.DataFrame,
    ctcae_dict_csv: str,
    medcpt_model_dir: str,
) -> pd.DataFrame:
    if ae_df.empty:
        print("âš ï¸ æ²¡æœ‰ AE å¯æ˜ å°„ã€‚")
        return ae_df

    # è¯»å– CTCAE è¯è¡¨
    ctcae_df = pd.read_csv(ctcae_dict_csv)
    ctcae_df.columns = ctcae_df.columns.str.strip()
    ctcae_terms = (
        ctcae_df["CTCAE Term"]
        .dropna()
        .astype(str)
        .str.strip()
        .str.lower()
        .unique()
        .tolist()
    )

    # åŠ è½½ MedCPT
    print("â³ åŠ è½½ MedCPT æ¨¡å‹...")
    tokenizer = AutoTokenizer.from_pretrained(medcpt_model_dir)
    model = AutoModel.from_pretrained(medcpt_model_dir)
    model.eval()

    device = "cuda" if torch.cuda.is_available() else "cpu"
    model.to(device)

    # ç¼–ç  CTCAE è¯è¡¨ï¼ˆä¿å­˜åœ¨ CPUï¼Œå¯ä»¥èŠ‚çœæ˜¾å­˜ï¼‰
    def encode_list(texts):
        embs = []
        for t in texts:
            t = str(t)
            inputs = tokenizer(
                t,
                return_tensors="pt",
                truncation=True,
                padding=True,
                max_length=64,
            )
            inputs = {k: v.to(device) for k, v in inputs.items()}
            with torch.no_grad():
                outputs = model(**inputs)
                cls_emb = outputs.last_hidden_state[:, 0, :]
                norm_emb = F.normalize(cls_emb, p=2, dim=1)
                # ä¿å­˜åœ¨ CPUï¼ŒèŠ‚çœ GPU æ˜¾å­˜
                embs.append(norm_emb[0].cpu())
        return torch.stack(embs)

    print("â³ ç¼–ç  CTCAE æœ¯è¯­...")
    ctcae_embeddings_cpu = encode_list(ctcae_terms)

    # AE â†’ top-3 CTCAE
    print("â³ åŒ¹é… AE â†’ Top-3 CTCAE ...")
    top_k = 3
    topk_rows = []

    for ctcae_free in ae_df["CTCAE"]:
        inputs = tokenizer(
            ctcae_free,
            return_tensors="pt",
            truncation=True,
            padding=True,
            max_length=64,
        )
        inputs = {k: v.to(device) for k, v in inputs.items()}
        with torch.no_grad():
            outputs = model(**inputs)
            ae_emb = F.normalize(outputs.last_hidden_state[:, 0, :], p=2, dim=1)

        # â­â­â­ å…³é”®ä¿®å¤ï¼šæŠŠ CPU embeddings ä¸´æ—¶ç§»åŠ¨åˆ° GPU
        ctcae_embeddings = ctcae_embeddings_cpu.to(device)

        sim = torch.mm(ae_emb, ctcae_embeddings.T).squeeze()
        topk_scores, topk_indices = torch.topk(sim, k=top_k)

        row = {}
        for rank, (idx, score) in enumerate(zip(topk_indices, topk_scores), start=1):
            row[f"CTCAE_Mapped_Top{rank}"] = ctcae_terms[idx].title()
            row[f"Similarity_Top{rank}"] = float(score)
        topk_rows.append(row)

    topk_df = pd.DataFrame(topk_rows)
    df = pd.concat([ae_df.reset_index(drop=True), topk_df.reset_index(drop=True)], axis=1)

    # ç²¾ç¡®åŒ¹é… + Final_CTCAE_Term
    ctcae_set = set(ctcae_terms)

    def exact_match(term):
        if isinstance(term, str) and term.lower() in ctcae_set:
            return term
        return None

    df["CTCAE_Mapped_Exact"] = df["CTCAE_Mapped_Top1"].apply(exact_match)
    df["CTCAE_Mapped_By"] = df["CTCAE_Mapped_Exact"].apply(
        lambda x: "exact" if x is not None else "semantic"
    )
    df["Final_CTCAE_Term"] = df["CTCAE_Mapped_Exact"].combine_first(
        df["CTCAE_Mapped_Top1"]
    )

    # é‡å‘½ååˆ—
    df = df.rename(
        columns={
            "Attribution to Disease": "Attr to Disease",
            "Immune-related AE": "AE Immune related?",
            "Serious AE": "Serious Y/N",
        }
    )

    # å»é‡
    df = df.drop_duplicates(
        subset=["MRN", "Onset Date", "CTCAE", "Grade", "Final_CTCAE_Term"]
    )

    final_cols = [
        "MRN",
        "Onset Date",
        "Date Resolved",
        "CTCAE",
        "Grade",
        "Attr to Disease",
        "AE Immune related?",
        "Serious Y/N",
        "CTCAE_Mapped_Top1",
        "Similarity_Top1",
        "Final_CTCAE_Term",
    ]
    for c in final_cols:
        if c not in df.columns:
            df[c] = ""

    return df[final_cols]


# ============= 4. æ•´ä¸ª pipelineï¼šåªè¾“å‡ºæœ€ç»ˆ step3 CSV =============
def run_pipeline(
    note_csv_path: str,
    baseline_file: str | None,
    ctcae_dict_csv: str,
    medcpt_model_dir: str,
    final_output_csv: str,
):
    # Step 1: GPT æŠ½ AE
    ae_df = gpt_extract_ae(note_csv_path)

    # Step 2: baseline è¿‡æ»¤ï¼ˆå¯é€‰ï¼‰
    ae_filtered = filter_with_baseline(ae_df, baseline_file)

    # Step 3: MedCPT æ˜ å°„
    final_df = map_to_ctcae_medcpt(ae_filtered, ctcae_dict_csv, medcpt_model_dir)

    # ğŸ‘‰ åªæœ‰è¿™é‡Œå†™å‡ºä¸€ä¸ªæœ€ç»ˆæ–‡ä»¶
    final_df.to_csv(final_output_csv, index=False)
    print(f"\nğŸ‰ å…¨éƒ¨å®Œæˆï¼æœ€ç»ˆç»“æœ CSVï¼š{final_output_csv}")

    HISTORY_DIR = "/netmnt/vast01/cbb01/lulab/gey2/AE_extraction/AE_Extraction_CTCAE_Map/ae_history"

    merged_df = update_patient_history(
        ae_new_df=final_df,
        history_dir=HISTORY_DIR,
        mrn_col="MRN",
    )

    # å¯é€‰ï¼šåªç”¨äº debug / å‰ç«¯ä¸´æ—¶æŸ¥çœ‹ï¼ˆä¸æ˜¯å¿…é¡»ï¼‰
    latest_path = "/netmnt/vast01/cbb01/lulab/gey2/AE_extraction/AE_Extraction_CTCAE_Map/latest_merged.csv"
    merged_df.to_csv(latest_path, index=False)
    print(f"âœ… latest merged saved -> {latest_path}")

    # âœ… æœ€å…³é”®ï¼šreturn merged_dfï¼ˆè¿™æ ·å‰ç«¯/è°ƒç”¨æ–¹å¯ä»¥ç›´æ¥æ‹¿åˆ°â€œæœ€æ–° AE listâ€ï¼‰
    return merged_df

# ============= 5. ç›´æ¥è·‘è„šæœ¬ç”¨ =============
if __name__ == "__main__":

    # 1. notes CSVï¼ˆä½ ç°åœ¨ç”¨çš„ progress_noteï¼Œé‚£ä¸€ç‰ˆæœ‰ Document Text / mrn / Document Date / Document Nameï¼‰
    NOTES_CSV = "/netmnt/vast01/cbb01/lulab/gey2/AE_extraction/AE_Extraction_CTCAE_Map/reversed_Clindoc266614-1_05_progress_note.csv"

    # 2. baseline æ–‡ä»¶ï¼ˆæœ‰å°±å†™è·¯å¾„ï¼Œæ²¡æœ‰å°±å†™ "" æˆ– Noneï¼‰
    BASELINE_XLSX = "/netmnt/vast01/cbb01/lulab/gey2/AE_extraction/AE_Extraction_CTCAE_Map/18C0056_BL_Subgroup_02.xlsx"   

    # 3. CTCAE è¯è¡¨ CSV
    CTCAE_DICT_CSV = "/netmnt/vast01/cbb01/lulab/gey2/AE_extraction/AE_Extraction_CTCAE_Map/CTCAE_v5.0.csv"

    # 4. ä½  finetune å¥½çš„ MedCPT æ¨¡å‹ç›®å½•
    MEDCPT_MODEL_DIR = "/netmnt/vast01/cbb01/lulab/gey2/AE_extraction/AE_Extraction_CTCAE_Map/medcpt_ctcae_triplet_epoch10"

    # 5. æœ€ç»ˆè¾“å‡º CSVï¼ˆåªæœ‰è¿™ä¸€ä¸ªï¼‰
    FINAL_OUTPUT_CSV = "/netmnt/vast01/cbb01/lulab/gey2/AE_extraction/AE_Extraction_CTCAE_Map/pipeline_ae_with_ctcae_note44.csv"

    # ====== å¼€å§‹è·‘ ======
    run_pipeline(
        note_csv_path=NOTES_CSV,
        baseline_file=BASELINE_XLSX,
        ctcae_dict_csv=CTCAE_DICT_CSV,
        medcpt_model_dir=MEDCPT_MODEL_DIR,
        final_output_csv=FINAL_OUTPUT_CSV,
    )

